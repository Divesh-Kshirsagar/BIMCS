{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boiler Digital Twin - LSTM Model Training\n",
    "\n",
    "This notebook trains an LSTM model to predict Boiler Steam Temperature based on control inputs.\n",
    "\n",
    "**Physics Logic:** Higher valve position (TV_8329ZC) adds cooling spray â†’ Lower temperature (TE_8332A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.csv...\n",
      "âœ“ Loaded 86400 rows from data.csv\n",
      "Columns: ['valve_position', 'pressure', 'flow_rate', 'temperature']\n",
      "\n",
      "First few rows:\n",
      "   valve_position  pressure  flow_rate  temperature\n",
      "0           17.05   -142.28   47312.49       538.29\n",
      "1           17.06   -142.79   47093.44       538.29\n",
      "2           17.06   -135.23   47659.94       538.25\n",
      "3           17.06   -147.23   47159.53       538.25\n",
      "4           17.06   -147.91   46381.55       538.25\n"
     ]
    }
   ],
   "source": [
    "# Try to load actual data, fallback to synthetic if not available\n",
    "try:\n",
    "    print(\"Loading data.csv...\")\n",
    "    df = pd.read_csv('data.csv')\n",
    "    \n",
    "    # Select required columns\n",
    "    required_cols = ['TV_8329ZC.AV_0#', 'PT_8313A.AV_0#', 'FT_8301.AV_0#', 'TE_8332A.AV_0#']\n",
    "    df = df[required_cols].copy()\n",
    "    \n",
    "    # Rename for clarity\n",
    "    df.columns = ['valve_position', 'pressure', 'flow_rate', 'temperature']\n",
    "    \n",
    "    print(f\"âœ“ Loaded {len(df)} rows from data.csv\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except (FileNotFoundError, KeyError) as e:\n",
    "    print(f\"âš  Could not load data.csv: {e}\")\n",
    "    print(\"Generating synthetic data for testing...\")\n",
    "    \n",
    "    # Generate synthetic data with physics-based relationship\n",
    "    n_samples = 10000\n",
    "    t = np.linspace(0, 100, n_samples)\n",
    "    \n",
    "    # Valve position varies (main control variable)\n",
    "    valve = 50 + 30 * np.sin(0.1 * t) + np.random.normal(0, 3, n_samples)\n",
    "    \n",
    "    # Context variables\n",
    "    pressure = 101 + 5 * np.sin(0.05 * t) + np.random.normal(0, 0.5, n_samples)\n",
    "    flow = 45 + 10 * np.sin(0.08 * t) + np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Temperature: INVERSE relationship with valve (physics-based)\n",
    "    # Higher valve â†’ more cooling â†’ lower temp\n",
    "    base_temp = 540\n",
    "    temp_reduction = -0.5 * valve  # Negative coefficient for inverse relationship\n",
    "    pressure_effect = 0.2 * pressure\n",
    "    flow_effect = 0.1 * flow\n",
    "    \n",
    "    temperature = base_temp + temp_reduction + pressure_effect + flow_effect + np.random.normal(0, 2, n_samples)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'valve_position': valve,\n",
    "        'pressure': pressure,\n",
    "        'flow_rate': flow,\n",
    "        'temperature': temperature\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ“ Generated {len(df)} synthetic samples\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping NaN: 86400\n",
      "Rows after dropping NaN: 86400\n",
      "\n",
      "Data statistics:\n",
      "       valve_position      pressure     flow_rate   temperature\n",
      "count    86400.000000  86400.000000  86400.000000  86400.000000\n",
      "mean        16.082346   -137.711768  46462.882509    537.521130\n",
      "std          4.857964     55.383279   1698.989047      4.328549\n",
      "min          1.640000   -484.700000  40773.290000    517.050000\n",
      "25%         12.540000   -171.240000  45286.340000    534.690000\n",
      "50%         16.080000   -135.320000  46491.070000    537.710000\n",
      "75%         18.990000   -100.400000  47610.840000    540.570000\n",
      "max         35.480000     75.330000  53047.270000    550.490000\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values\n",
    "print(f\"Rows before dropping NaN: {len(df)}\")\n",
    "df = df.dropna()\n",
    "print(f\"Rows after dropping NaN: {len(df)}\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nData statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing features...\n",
      "âœ“ Scaled data shape: (86400, 4)\n",
      "  Features: valve_position, pressure, flow_rate, temperature\n",
      "âœ“ Saved scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Normalize features (0-1 range)\n",
    "print(\"\\nNormalizing features...\")\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df.values)\n",
    "\n",
    "print(f\"âœ“ Scaled data shape: {scaled_data.shape}\")\n",
    "print(f\"  Features: valve_position, pressure, flow_rate, temperature\")\n",
    "\n",
    "# Save scaler for later use\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"âœ“ Saved scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sequences with length 60...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cbef4a7262411cbb238e5f0f3b573a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating sequences:   0%|          | 0/86340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created 86340 sequences\n",
      "  X shape: (86340, 60, 4) (samples, timesteps, features)\n",
      "  y shape: (86340,) (samples,)\n"
     ]
    }
   ],
   "source": [
    "# Create sequences (60 timesteps to predict next step)\n",
    "SEQUENCE_LENGTH = 60\n",
    "\n",
    "def create_sequences(data, seq_len):\n",
    "    X, y = [], []\n",
    "    for i in tqdm(range(len(data) - seq_len), desc=\"Creating sequences\"):\n",
    "        # Input: 60 timesteps of [valve, pressure, flow, temp]\n",
    "        X.append(data[i:i+seq_len])\n",
    "        # Output: next temperature value (index 3)\n",
    "        y.append(data[i+seq_len, 3])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(f\"\\nCreating sequences with length {SEQUENCE_LENGTH}...\")\n",
    "X, y = create_sequences(scaled_data, SEQUENCE_LENGTH)\n",
    "\n",
    "print(f\"âœ“ Created {len(X)} sequences\")\n",
    "print(f\"  X shape: {X.shape} (samples, timesteps, features)\")\n",
    "print(f\"  y shape: {y.shape} (samples,)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train/Test Split:\n",
      "  Training samples: 69072\n",
      "  Testing samples: 17268\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain/Test Split:\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building LSTM model...\n",
      "âœ“ Model architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\B.I.M.C.S\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,000</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚        \u001b[38;5;34m11,000\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m51\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,051</span> (43.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,051\u001b[0m (43.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,051</span> (43.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,051\u001b[0m (43.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build model\n",
    "print(\"\\nBuilding LSTM model...\")\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(SEQUENCE_LENGTH, 4), return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"âœ“ Model architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting training...\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0485 - val_loss: 2.0676e-04 - val_mae: 0.0124\n",
      "Epoch 2/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 8.2122e-04 - mae: 0.0210 - val_loss: 1.0637e-04 - val_mae: 0.0087\n",
      "Epoch 3/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.9981e-04 - mae: 0.0144 - val_loss: 1.0500e-04 - val_mae: 0.0081\n",
      "Epoch 4/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.6586e-04 - mae: 0.0135 - val_loss: 3.6140e-05 - val_mae: 0.0046\n",
      "Epoch 5/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.4692e-04 - mae: 0.0130 - val_loss: 3.9963e-05 - val_mae: 0.0041\n",
      "Epoch 6/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.3482e-04 - mae: 0.0127 - val_loss: 3.6075e-05 - val_mae: 0.0051\n",
      "Epoch 7/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.3368e-04 - mae: 0.0125 - val_loss: 1.4024e-05 - val_mae: 0.0028\n",
      "Epoch 8/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2980e-04 - mae: 0.0125 - val_loss: 2.8250e-05 - val_mae: 0.0039\n",
      "Epoch 9/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2554e-04 - mae: 0.0123 - val_loss: 4.2683e-05 - val_mae: 0.0048\n",
      "Epoch 10/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2098e-04 - mae: 0.0122 - val_loss: 4.5246e-05 - val_mae: 0.0061\n",
      "Epoch 11/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1598e-04 - mae: 0.0121 - val_loss: 5.6925e-05 - val_mae: 0.0054\n",
      "Epoch 12/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.2583e-04 - mae: 0.0122 - val_loss: 1.2634e-05 - val_mae: 0.0027\n",
      "Epoch 13/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1145e-04 - mae: 0.0120 - val_loss: 3.0048e-05 - val_mae: 0.0040\n",
      "Epoch 14/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1000e-04 - mae: 0.0119 - val_loss: 2.7860e-05 - val_mae: 0.0042\n",
      "Epoch 15/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - loss: 3.1057e-04 - mae: 0.0120 - val_loss: 8.8184e-06 - val_mae: 0.0024\n",
      "Epoch 16/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.1036e-04 - mae: 0.0119 - val_loss: 3.3248e-05 - val_mae: 0.0048\n",
      "Epoch 17/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.0906e-04 - mae: 0.0119 - val_loss: 2.0389e-05 - val_mae: 0.0037\n",
      "Epoch 18/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.0891e-04 - mae: 0.0118 - val_loss: 1.9459e-05 - val_mae: 0.0027\n",
      "Epoch 19/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.0811e-04 - mae: 0.0118 - val_loss: 2.0201e-05 - val_mae: 0.0040\n",
      "Epoch 20/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 3.0628e-04 - mae: 0.0118 - val_loss: 1.0781e-05 - val_mae: 0.0025\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\n",
      "============================================================\n",
      "âœ“ Training completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1  # Show progress for each epoch\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ Training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on test set...\n",
      "\n",
      "ğŸ“Š Model Performance:\n",
      "  Test Loss (MSE): 0.000009\n",
      "  Test MAE: 0.002371\n",
      "\n",
      "Sample predictions (normalized):\n",
      "  Sample 1: Predicted=0.5766, Actual=0.5786\n",
      "  Sample 2: Predicted=0.7137, Actual=0.7162\n",
      "  Sample 3: Predicted=0.5978, Actual=0.6044\n",
      "  Sample 4: Predicted=0.5806, Actual=0.5757\n",
      "  Sample 5: Predicted=0.5441, Actual=0.5437\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nğŸ“Š Model Performance:\")\n",
    "print(f\"  Test Loss (MSE): {test_loss:.6f}\")\n",
    "print(f\"  Test MAE: {test_mae:.6f}\")\n",
    "\n",
    "# Sample predictions\n",
    "print(\"\\nSample predictions (normalized):\")\n",
    "sample_preds = model.predict(X_test[:5], verbose=0)\n",
    "for i in range(5):\n",
    "    print(f\"  Sample {i+1}: Predicted={sample_preds[i][0]:.4f}, Actual={y_test[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Model saved as 'boiler_model.keras'\n",
      "âœ“ Scaler saved as 'scaler.pkl'\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ALL DONE! Model training complete.\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Use 'boiler_model.keras' for predictions\n",
      "  2. Use 'scaler.pkl' to normalize input data\n",
      "  3. Run 'python main.py' to start the FastAPI server\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('boiler_model.keras')\n",
    "print(\"\\nâœ“ Model saved as 'boiler_model.keras'\")\n",
    "print(\"âœ“ Scaler saved as 'scaler.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ALL DONE! Model training complete.\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Use 'boiler_model.keras' for predictions\")\n",
    "print(\"  2. Use 'scaler.pkl' to normalize input data\")\n",
    "print(\"  3. Run 'python main.py' to start the FastAPI server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
